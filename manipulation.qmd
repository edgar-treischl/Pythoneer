---
title: "Data manipulation"
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
reticulate::use_python("/Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/bin/python")

```

What is dplyr? The dplyr package is designed for data manipulation, written and maintained by Hadley Wickham. It is part of the tidyverse, an ecosystem of packages designed with common APIs and a shared philosophy. Dplyr is designed to abstract common data manipulation tasks into a consistent API. However, the pandas library provides similar functions. The pandas package is a powerful data manipulation library in Python. It provides data structures and functions to manipulate data and in this chapter we will see how to use dplyr functions work in Python. 

First, we need to import the necessary libraries. We will use pandas and seaborn. Furthermore, we will load the penguins dataset with `load_dataset` from seaborn. Let us have a look at the first five rows of the dataset with the .head function. 



```{python}
#Import libraries
import pandas as pd
import seaborn as sns

#Load dataset
penguins = sns.load_dataset("penguins")
```
How does the dataset look like? The .head() function is used to show the first five rows of the dataset. The .tail() function is used to show the last five rows of the dataset. The .shape function is used to show the dimensions of the dataset. Overall, the penguins dataset contains 333 entries and 7 columns. The columns are for example species, island, and body_mass


```{python}
#Inspect the first five rows of the dataset
penguins.head()
```



Maybe you did not realize it, but the penguins dataset contains missing values. The dropna function is used to remove missing values from the dataset. And we can append the .info() function to get an overview of the dataset. The .info() function shows the number of non-null entries in each column. The dataset contains 333 entries and 7 columns.


```{python}
#Drop missing values
penguins = penguins.dropna()

#Get an overview of the dataset
penguins.info()
```

If you want to know the type of the variables in the dataset, you can use the .dtypes function. The dtypes function shows the data types of the variables. In this dataset, the variables species, island, and sex are of type object. Or variable bill_length_mm is of type float64.

```{python}
#data types of the variables
penguins.dtypes
```




## Filter

A common task in data manipulation is to filter the dataset. Suppose you want to filter the penguins dataset and apply an analysis only for observations for the species Adelie. Use .query() to filter the dataset. The query function is a powerful tool to filter datasets. Append .query() to the dataset and specify the condition you want to filter for. 


```{python}
#Filter penguis dataset where species is Adelie
penguins.query('species == "Adelie"').head()
```


You can also filter for multiple conditions. Say you want to filter for the species Adelie, but only if the sex of the penguins is not male.



```{python}
#Filter data with mulqitple conditions
penguins.query('species == "Adelie" & sex != "Male" ').head()
```





## Arrange

Sometimes it is handy to sort the dataset. The .sort_values() function is used to sort the dataset. Append .sort_values()  to the dataset and specify the variable you want to sort by.


```{python}
#Sort variables
penguins.sort_values(by="body_mass_g").head()
```

In other instances, you might want to sort the descendingly. The ascending parameter is used to sort the dataset in ascending order. By default, the ascending parameter is set to True. Set ascending to FALSE to sort the variable in descending order.


```{python}
#Sort variables descendingly
penguins.sort_values(by="body_mass_g", ascending=False).head()
```


## Select

Large datasets often contain many variables and are difficult to work with. The select function is used to select variables. For example, put the columns species and island in brackets to select them.


```{python}
#Select columns
penguins[['species', 'island']].head()
```

Another way to select columns is to use the .loc function. The latter is used to access a group of rows and columns by labels or a boolean array. For example, select all columns from island to bill_depth_mm.



```{python}
#select columns with .loc: from island to bill_depth_mm
penguins.loc[:, 'island':'bill_depth_mm'].head()
```

You can also select columns by their index. For example, select the first three columns of the dataset. Or suppose you want to check if a variable is in a specified set. Use the isin function to check if the variable is included in a set. For example, select the observations where the species is Adelie.


```{python}
#A set with the species Adelie
myset = ['Adelie']

#Select observations where the species isin the set
adelie = penguins[penguins["species"].isin(myset)]
adelie.head()
```


## Mutate

The mutate function is used to create new variables. We can use the assign function to create a new variable. For example, create a new variable weight which is a copy of the variable body_mass_g. Next, the .assign() function is used to create a new variable body_mass_kilo which is the body_mass_g divided by 1000. Feel free to manipulate the dataset and create new variables.



```{python}
# Create a new dataset
weight = penguins[['body_mass_g']]

#Assign a new variable by common operations
weight = weight.assign(body_mass_kilo = weight['body_mass_g'] /1000)
weight.head()
```


## Summarize

How to calculate summary statistics of the dataset? The summarize function is used to calculate summary statistics of the dataset. The .describe() function is used to calculate summary statistics of the dataset.

The summarize function is used to calculate summary statistics of the dataset. The .describe() function is used to calculate summary statistics of the dataset.

```{python}
#Describe the dataset
penguins.describe()
```

Another way to calculate summary statistics is to use the .groupby() function. The .groupby function provides the power of the split-apply-combine pattern. The .groupby function is used to split the dataset into groups. The .apply function is used to apply a function to each group. The .combine function is used to combine the results into a new dataset. For example, calculate the mean body_mass_g of the penguins grouped by sex. Append .groupby() to the dataset and specify the variable you want to group by. In addition, use the .mean() function to calculate the mean of the grouped variable.

```{python}
# .groupby() and .mean() to calculate the mean body_mass_g of the penguins
penguins[["sex", "body_mass_g"]].groupby("sex").mean()
```


The .groupby function can be used to group by multiple variables. For example, calculate the mean body_mass_g of the penguins grouped by sex and species.


```{python}
#Add several variables to group by
penguins.groupby(["sex", "species"])["body_mass_g"].mean()
```

Finally, the .count() function is used to count the number of entries in each category of a variable.


```{python}
#shortr penguins["species"].value_counts()
penguins.groupby("species")["species"].count()
```

### Summary{-}

In this script, we have shown how to use dplyr functions in Python. Keep in mind that the dplyr package is designed for data manipulation in R. However, the pandas library in Python provides similar functions to dplyr. Aggregation statistics can be calculated on entire columns or rows. The groupby function provides the power of the split-apply-combine pattern. The value_counts is a convenient shortcut to count the number of entries in each category of a variable. 

The .loc function is used to access a group of rows and columns by labels or a boolean array. Say we want to create a indicator variable Adelie. The .loc function is used to create a new variable Adelie. The first line of code creates a new variable Adelie with the .loc function. The second line of code fills the rest of the column with False. The third line of code selects the columns species and Adelie.


```{python}
# Create a new variable with the .loc function
penguins.loc[penguins['species'] == "Adelie", 'Adelie'] = 'True' 

#Fill the rest of the column with False
penguins.loc[penguins['species'] != "Adelie", 'Adelie'] = 'False' 

#Select the columns species and Adelie
penguins[['species', 'Adelie']].head()
```

So say we want to create a new variable check_length which checks if the bill_length_mm is less than or equal to 40. The .apply() function is used to apply a function along an axis of the dataframe. For example, the lambda function is used to create a new variable check_length. It checks if the bill_length_mm is less than or equal to 40. If not, the function returns False. If the condition is met, the function returns True.


```{python}
# Create a new variable check_length: check if the bill_length_mm is less than or equal to 40
penguins['check_length'] = penguins['bill_length_mm'].apply(lambda x: 'True' if x <= 40 else 'False')

#Select the columns bill_length_mm and check_length
penguins[['bill_length_mm', 'check_length']].head()
```


