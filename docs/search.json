[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pythoneer",
    "section": "",
    "text": "Preface\nWelcome to the Pythoneer website. The Pythoneer project aims to support the transition of R user into the Python world. There are several reasons why it can be beneficial to learn Python even if you know R:\n\nVersatility: While R is a great language for statistical analysis and data visualization, Python is a more general-purpose language that can be used for a wider variety of tasks, such as web development, machine learning, and scientific computing.\nLarge and active community: Python has a much larger and more active community than R, which means that there are more resources and support available if you run into problems or want to learn new things.\nPopularity in industry: Python is widely used in industry, particularly in areas such as data science and machine learning, so learning Python can make you more competitive in the job market.\nIntegration with other tools: Python has many libraries and packages that allow it to integrate with other tools, such as databases, big data frameworks, and cloud computing platforms, making it a more flexible and powerful tool for data analysis and computation.\nDifferent approaches to problem-solving: R and Python have different approaches to problem-solving and data analysis, so learning both can expand your skill set and enable you to tackle a wider range of problems.\n\nKeep in mind that the project is work in progress and at a very early stage.\n\n#Print with Python\nprint(\"Hello Python World\")\n\nHello Python World"
  },
  {
    "objectID": "intro.html#how-not-to-calculate-basic-statistics",
    "href": "intro.html#how-not-to-calculate-basic-statistics",
    "title": "1  Introduction",
    "section": "How (not) to calculate basic statistics",
    "text": "How (not) to calculate basic statistics\nThe last Python book I read, introduced probably over a hundred pages about the different data structure, and of course, we need to know that to handle Python. I certainly don’t argue about this point, but instead of providing me meaningful examples to illustrate this point, I am reading about about artificial examples that not even work when I copied the code and run it in my own console. Well, shit happens, don’t you think? I really started to get the creep as I reached a statistics section. Let’s see what I learned from this chapter.\nIn Python, you have to import the according libraries and install first, in case you work with a library the very first time. We will cover these points later, for the moment it is enough to look at the Python code and output. So, I import the seaborn package in order to have some data at hand. The seaborn.get_dataset_names() function returns all available data sets.\n\n#import seaborn to get some data\nimport seaborn as sns\nsns.get_dataset_names()\n\n#&gt; ['anagrams', 'anscombe', 'attention', 'brain_networks', 'car_crashes', 'diamonds', 'dots', 'dowjones', 'exercise', 'flights', 'fmri', 'geyser', 'glue', 'healthexp', 'iris', 'mpg', 'penguins', 'planets', 'seaice', 'taxis', 'tips', 'titanic']\n\n\nWe can save the mpg data under the name cars and use the print function to examine the data.\n\n#use the mpg data set as cars\ncars = sns.load_dataset(\"mpg\") \nprint(cars)\n\n#&gt;       mpg  cylinders  ...  origin                       name\n#&gt; 0    18.0          8  ...     usa  chevrolet chevelle malibu\n#&gt; 1    15.0          8  ...     usa          buick skylark 320\n#&gt; 2    18.0          8  ...     usa         plymouth satellite\n#&gt; 3    16.0          8  ...     usa              amc rebel sst\n#&gt; 4    17.0          8  ...     usa                ford torino\n#&gt; ..    ...        ...  ...     ...                        ...\n#&gt; 393  27.0          4  ...     usa            ford mustang gl\n#&gt; 394  44.0          4  ...  europe                  vw pickup\n#&gt; 395  32.0          4  ...     usa              dodge rampage\n#&gt; 396  28.0          4  ...     usa                ford ranger\n#&gt; 397  31.0          4  ...     usa                 chevy s-10\n#&gt; \n#&gt; [398 rows x 9 columns]\n\n\nSo, what did I learn in the chapter? Well, how can we calculate an mean with Python? Shouldn’t be that though. I know how to calculate a mean by hand since my early days of school and how it is done in a statistic software. The authors offered me the following solution:\n\ndef mean (array): \n    n = len(array)\n    return sum(array) / n\n\nmean(cars.mpg)\n\n#&gt; 23.514572864321615\n\n\nIn the code snippet we define the function mean to create a mean, within this function we define n as the length(len) of the array and the functions returns a value, which divides the sum of the array by the length n. Fine. That’s exactly a cool way to show us how a functions works. We have to provide a name of a function, tell Python what the function should do, in this case with an array of numbers.\nIn my experience, I always learned how functions and other concepts work in much more artificial way. Look how I learned how a function works in Python:\n\n#Create your own function\ndef hello(name):\n    return (f\"Hallo, {name}! How are you?\")\n\n# Call the function and give value for the input name\nhello(\"Edgar\")\n\n#&gt; 'Hallo, Edgar! How are you?'\n\n\nThus, we create the hello function that returns a sentence and inserts the name of the input value. Nothing wrong about that, even though calculating a mean seems a little bit more realistic to illustrate why we need such a function.\nAnyway, in the next steps the author gives us a function for the mean, a function for the median, a function for the modus, a function to calculate the variance and, I am dead serious, other functions for others measure of central tendency. Come on, this guy can’t be serious, we should learn how this works in practice. Use NumPy to get the scientific toolkit and pandas for tabular processing and the presentation of data. The latter comes with a lot of functions we can use them in order to calculate basic statistics and more advanced stuff. Use the describe function to get an overview about the data. Let’s see how it works.\n\nimport numpy as np\nimport pandas as pd\n\ncars.describe()\n\n#&gt;               mpg   cylinders  ...  acceleration  model_year\n#&gt; count  398.000000  398.000000  ...    398.000000  398.000000\n#&gt; mean    23.514573    5.454774  ...     15.568090   76.010050\n#&gt; std      7.815984    1.701004  ...      2.757689    3.697627\n#&gt; min      9.000000    3.000000  ...      8.000000   70.000000\n#&gt; 25%     17.500000    4.000000  ...     13.825000   73.000000\n#&gt; 50%     23.000000    4.000000  ...     15.500000   76.000000\n#&gt; 75%     29.000000    8.000000  ...     17.175000   79.000000\n#&gt; max     46.600000    8.000000  ...     24.800000   82.000000\n#&gt; \n#&gt; [8 rows x 7 columns]\n\n\nSo, we have to append the describe() function to the saved cars data in order to get an overview of the central tendency measures. You can do the same with all other functions that calculate other measures, such as the mean or standard deviance:\n\ncars.mean()\n\n#&gt; mpg               23.514573\n#&gt; cylinders          5.454774\n#&gt; displacement     193.425879\n#&gt; horsepower       104.469388\n#&gt; weight          2970.424623\n#&gt; acceleration      15.568090\n#&gt; model_year        76.010050\n#&gt; dtype: float64\n\ncars.std()\n\n#&gt; mpg               7.815984\n#&gt; cylinders         1.701004\n#&gt; displacement    104.269838\n#&gt; horsepower       38.491160\n#&gt; weight          846.841774\n#&gt; acceleration      2.757689\n#&gt; model_year        3.697627\n#&gt; dtype: float64\n\n\nSo, what you do think? Shall we learn how to define our own function to calculate the mean or choose the easy way and let a package calculate the “hard” stuff for us. I would say both. We learned on this entry how to write an own function by solving a real-world problem. In case we didn’t know how to calculate a mean in Python we could use a function and I provided you on purpose with a second example to show you how many others explain a function. However, after learning what a function is, we need to know how we could work and spent our time more efficiently.\nThis point becomes bothersome if we spent too much of our time with things that have a simple solution. For instance, guess what the next code does. And I guess you will skip the code after line 2, well that’s at least what recommend if you know what a correlation is.\n\nimport math\ndef correlation(x, y):\n    n = len(x) \n    \n    # Means\n    x_mn = sum(x) / n \n    y_mn = sum(y) / n\n    \n    # Variance\n    var_x = (1 / (n-1)) * sum(map(lambda xi: (xi - x_mn) ** 2 , x)) \n    var_y = (1 / (n-1)) * sum(map(lambda yi: (yi - y_mn) ** 2 , y))\n    \n    # Std\n    std_x, std_y = math.sqrt(var_x), math.sqrt(var_y)\n    \n    # Covariance\n    xy_var = map(lambda xi, yi: (xi - x_mn) * (yi - y_mn), x, y) \n    cov = (1 / (n-1)) * sum(xy_var)\n    \n    # Pearson's R\n    r = cov / (std_x * std_y) \n    return float(f\"{r:.3f}\")\n\n# Some data\nsize = [20, 15, 40, 25, 35]\ncost = [300, 400, 600, 700, 666]\n\nprint(correlation(size, cost))\n\n#&gt; 0.666\n\n\nIt’s the “devil’s code”! Of course, I am just kidding, but please don’t get me wrong. I think it is very useful to see how a correlation coefficients is calculated. You should do it at least once per hand if you learn the concept for the first time. But in my case I don’t have to learn what a correlation is. Let’s learn how Python works, but in an efficient way:\n\nnp.corrcoef(size, cost)\n\n#&gt; array([[1.        , 0.66645893],\n#&gt;        [0.66645893, 1.        ]])\n\n\nAnd we should at least look at the scatter plot in case we talk about correlations. The matplotlib provides a lot of different graphs for us.\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.style.use('ggplot')\n\nplt.scatter(cars.mpg, cars.horsepower)\n\n\n\n\nAnd in case you are an R user, you can even use the ggplot2 style, just to let you show some possibilities. But of course, we have to think more systematically how we can reach our goal in the next chapter."
  },
  {
    "objectID": "firststeps.html",
    "href": "firststeps.html",
    "title": "2  First steps",
    "section": "",
    "text": "Python and R are both popular programming languages used for data analysis and machine learning tasks. While both languages have their own strengths and weaknesses, there are situations where using both languages together can be beneficial.\nusing Python and R together can be beneficial when you want to take advantage of the strengths of both languages. Whether you want to use R libraries in Python, Python libraries in R, or combine both languages in a single application, there are many options available for integrating Python and R. Here are some ways in which Python can be used with R:\n\nR can be called from Python using the “rpy2” package: rpy2 is a Python package that allows Python programs to call R functions and use R data structures. This can be useful when you want to use an R library that is not available in Python or when you have existing R code that you want to integrate into your Python program.\nJupyter Notebooks can be used to combine Python and R code: Jupyter Notebooks are interactive documents that allow you to combine code, text, and visualizations in a single document. Jupyter Notebooks support both Python and R, so you can use both languages in the same notebook.\nShiny applications can be built using Python: Shiny is a popular web framework for building interactive web applications in R. However, Shiny also supports using Python through the “reticulate” package. This can be useful when you want to use a Python library that is not available in R or when you have existing Python code that you want to integrate into your Shiny application.\nFinally, Python can be called from R using the reticulate package: Reticulate is a package that allows R programs to call Python functions and use Python data structures. This can be useful when you want to use a Python library that is not available in R or when you have existing Python code that you want to integrate into your R program (Ushey, Allaire, and Tang 2023).\n\nThe reticulate package makes it easy for R users to incorporate Python functionality into their R workflows, whether it’s using Python libraries not available in R, reusing existing Python code, or simply taking advantage of Python’s strengths in specific areas such as machine learning or web development.\n\nPython environment management: The package provides tools to manage Python environments within R, including creating and configuring virtual environments and managing package dependencies.\nCalling Python code: The package provides functions to call Python code from R, including importing Python modules, calling Python functions, and accessing Python objects. Passing data between R and Python: The package allows for seamless integration between R and Python data structures. For example, R data frames can be converted to Python pandas data frames and vice versa.\nInteractive sessions: The package provides an interactive Python console within R sessions, allowing users to execute Python commands interactively.\nPlotting: The package allows R users to create Python plots using popular Python visualization libraries such as Matplotlib and Seaborn.\n\nFirst, you need to have Python installed on your system. You can download Python from the official website (https://www.python.org/downloads/) and install it following the instructions provided. Next, install the reticulate package: Open an R session and install the reticulate package by running the following command:\n\ninstall.packages(\"reticulate\")\n\nOnce the package is installed, you need to set the Python path in R. The Python path is the location of the Python executable on your system. You can set the path by running the following command:\n\nlibrary(reticulate)\nuse_python(\"/Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/bin/python\")\n\nIf you’re using the default Python installation on your system, you can skip this step. You can test the installation by running the following command:\n\npy_config()\n\npython:         /Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/bin/python\nlibpython:      /Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/lib/libpython3.8.dylib\npythonhome:     /Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate:/Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate\nversion:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:13)  [Clang 14.0.6 ]\nnumpy:          /Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/lib/python3.8/site-packages/numpy\nnumpy_version:  1.24.2\n\nNOTE: Python version was forced by use_python() function\n\n\nThis command should display information about your Python installation, including the Python version, the location of the Python executable, and the Python library path. Once the reticulate package is installed and configured, you can start using Python functionality in your R code. For example, you can import Python modules, call Python functions, and access Python objects directly from R.\nHowever, I’ll use a virtual environment for the book and the conda_list() functions returns all (conda) environment of the system.\n\n#List all conda installations\nconda_list()\n\n            name\n1           base\n2       EdgarGPT\n3      IliartBot\n4 IliartGPT.venv\n5          flask\n6         fuckit\n7   r-reticulate\n8 streamlit.venv\n                                                                 python\n1                     /Users/edgar/Library/r-miniconda-arm64/bin/python\n2       /Users/edgar/Library/r-miniconda-arm64/envs/EdgarGPT/bin/python\n3      /Users/edgar/Library/r-miniconda-arm64/envs/IliartBot/bin/python\n4 /Users/edgar/Library/r-miniconda-arm64/envs/IliartGPT.venv/bin/python\n5          /Users/edgar/Library/r-miniconda-arm64/envs/flask/bin/python\n6         /Users/edgar/Library/r-miniconda-arm64/envs/fuckit/bin/python\n7   /Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/bin/python\n8 /Users/edgar/Library/r-miniconda-arm64/envs/streamlit.venv/bin/python\n\n\nVirtual environments in Python are a useful tool for managing dependencies and ensuring that your project runs smoothly on different systems. Here are several reasons why it is wise to use virtual environments in Python:\n\nIsolation: When you create a virtual environment, you create a self-contained Python environment with its own installation of Python and any required packages. This means that the packages installed in one virtual environment do not interfere with packages installed in other virtual environments or the global Python environment. Isolating packages in this way reduces the risk of package version conflicts and makes it easier to manage dependencies.\nReproducibility: By using virtual environments, you can ensure that your code runs in a consistent and reproducible environment, regardless of the system it is run on. This is especially important if you plan to share your code with others or if you need to run your code on multiple systems.\nFlexibility: Virtual environments make it easy to switch between different Python versions or package configurations. This can be useful if you need to work on multiple projects that require different versions of Python or different package dependencies.\nSecurity: When you install packages in a virtual environment, you are not affecting the global Python installation on your system. This means that any security vulnerabilities or issues with the packages you install are contained within the virtual environment, reducing the risk of affecting other parts of your system.\n\nCreate a Python environment using the virtualenv_create() function. This function creates a new virtual environment and installs the specified packages. For example, to create a virtual environment called “myenv” and install the pandas package, you can run the following command:\n\nvirtualenv_create(\"myenv\", packages = \"pandas\")\n\nFinally, you can install additional Python packages using the py_install() function. This function installs the specified packages in the active Python environment. For example, to install the pandas package, you can run the following command:\n\npy_install(\"pandas\")\n\nThe next console achieves the same result with Conda and import the Pandas module.\n\n#install packages\nconda_install(\"r-reticulate\", \"pandas\")\npandas &lt;- import(\"pandas\")\n\nLet us explore some Python packages to see how we can intregrate them in R. For example, Seaborn is a visualization library based on Matplotlib. It provides a high-level interface for creating informative and attractive statistical graphics. It even gives us access to know data sets such as mtcars or Anscombe’s quartet.\nAnscombe’s quartet is a set of four datasets that have nearly identical descriptive statistics, yet have very different plots when graphed. The quartet was created by the statistician Francis Anscombe in 1973 to demonstrate the importance of visualizing data and the limitations of summary statistics. Each dataset consists of 11 (x, y) pairs, and the four datasets are designed to have the same mean, variance, correlation, and linear regression line. However, when plotted, each dataset reveals a very different relationship between x and y. The quartet is often used to illustrate the importance of data visualization and exploratory data analysis in understanding and interpreting statistical results.\n\nimport seaborn as sns\nsns.set_theme(style=\"ticks\")\n\n# Load the example dataset for Anscombe's quartet\ndf = sns.load_dataset(\"anscombe\")\n\n# Show the results of a linear regression within each dataset\nsns.lmplot(\n    data=df, x=\"x\", y=\"y\", col=\"dataset\", hue=\"dataset\",\n    col_wrap=2, palette=\"muted\", ci=None,\n    height=4, scatter_kws={\"s\": 50, \"alpha\": 1}\n)\n\n\n\n\n\n\n\nLet us load the “mpg” dataset and display the first few rows of the data. If you haven’t already, you’ll need to install Seaborn first (Waskom 2021).\nLoad Seaborn and the “mpg” dataset: Once you have Seaborn installed, you can load it and the “mpg” dataset using the following Python code. It imports the Seaborn package as “sns” and loads the “mpg” dataset into a variable called “cars”. Moreover, I also import the Pandas package which we will use as well.\n\n#import numpy as np\n#import pandas as pd\nimport seaborn as sns\nimport pandas as pd\n\ncars = sns.load_dataset(\"mpg\")\n\nTo display the first few rows of the “mpg” dataset, you can use the head() function from the Pandas library, which is included in the Seaborn package:\n\n#print(cars)\ncars.head()\n\n    mpg  cylinders  displacement  ...  model_year  origin                       name\n0  18.0          8         307.0  ...          70     usa  chevrolet chevelle malibu\n1  15.0          8         350.0  ...          70     usa          buick skylark 320\n2  18.0          8         318.0  ...          70     usa         plymouth satellite\n3  16.0          8         304.0  ...          70     usa              amc rebel sst\n4  17.0          8         302.0  ...          70     usa                ford torino\n\n[5 rows x 9 columns]\n\n\nThe Pandas library is a popular data analysis toolkit for Python. It provides a wide range of functions and tools for working with structured data. For example, the describe() function is used to generate descriptive statistics of a Pandas DataFrame or Series. When called on a DataFrame or Series, the describe() function provides summary statistics such as count, mean, standard deviation, minimum, maximum, and quartiles. The next console shows how to generate descriptive statistics for the “mpg” dataset using the describe() function, you can use the following Python code:\n\ncars.describe()\n\n              mpg   cylinders  ...  acceleration  model_year\ncount  398.000000  398.000000  ...    398.000000  398.000000\nmean    23.514573    5.454774  ...     15.568090   76.010050\nstd      7.815984    1.701004  ...      2.757689    3.697627\nmin      9.000000    3.000000  ...      8.000000   70.000000\n25%     17.500000    4.000000  ...     13.825000   73.000000\n50%     23.000000    4.000000  ...     15.500000   76.000000\n75%     29.000000    8.000000  ...     17.175000   79.000000\nmax     46.600000    8.000000  ...     24.800000   82.000000\n\n[8 rows x 7 columns]\n\n\nOr consider the mean() function which is used to calculate the arithmetic mean of a Pandas DataFrame or Series. When called on a DataFrame or Series, the mean() function calculates the average value of all the elements in the DataFrame or Series.\n\ncars.mean()\n\nmpg               23.514573\ncylinders          5.454774\ndisplacement     193.425879\nhorsepower       104.469388\nweight          2970.424623\nacceleration      15.568090\nmodel_year        76.010050\ndtype: float64\n\n&lt;string&gt;:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n\n\nScipy is a popular library for scientific computing in Python, and it provides functions for calculating statistical values, such as the correlation coefficient. Start by importing the necessary packages. You’ll need the scipy.stats module to calculate the correlation coefficient, and you may also need numpy to work with arrays or matrices of data.\n\nimport scipy\nimport scipy.stats as stats\nimport numpy as np\n\nThe scipy.stats module can calculate the correlation coefficient for two arrays, but if you have more than two variables, you’ll need to use a matrix. Use the stats.pearsonr() function to calculate the Pearson correlation coefficient. This function takes two arguments: the two arrays or matrices to compare, and it returns two values: the correlation coefficient and the p-value.\n\nmpg = cars[\"mpg\"]\nhorsepower = cars[\"horsepower\"]\n\nscipy.stats.pearsonr(mpg, horsepower)\n\narray must not contain infs or NaNs\n\n\nUnfortuntely, there is a missing values problem that we need to fix first. In Python, missing values are typically represented by the special value NaN (Not a Number), which is part of the numpy library. There are different ways to drop missing values from a dataset, depending on the context and the desired outcome.\nDrop rows or columns with missing values: If you have missing values in your dataset and you want to remove entire rows or columns that contain at least one missing value, you can use the dropna() method. This method removes all rows that contain at least one missing value by default, but you can specify the argument axis=1 to remove columns instead.\nIf you want to drop missing values only within a specific column, you can use the dropna() method with the subset argument. This argument specifies the column or columns to consider when dropping missing values. The next console shows the first approaches and the results of the correlation coeficient.\n\ncars = cars.dropna()\nmpg = cars[\"mpg\"]\nhorsepower = cars[\"horsepower\"]\n\nscipy.stats.pearsonr(mpg, horsepower)\n\nPearsonRResult(statistic=-0.7784267838977761, pvalue=7.031989029403436e-81)\n\n\nAlternatively, if you have a pandas DataFrame, you can use the pandas.DataFrame.corr() method to calculate the correlation coefficient for all pairs of columns.\n\ncorr_matrix = cars.corr(method='pearson')\n\n&lt;string&gt;:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n\nprint(corr_matrix)\n\n                   mpg  cylinders  ...  acceleration  model_year\nmpg           1.000000  -0.777618  ...      0.423329    0.580541\ncylinders    -0.777618   1.000000  ...     -0.504683   -0.345647\ndisplacement -0.805127   0.950823  ...     -0.543800   -0.369855\nhorsepower   -0.778427   0.842983  ...     -0.689196   -0.416361\nweight       -0.832244   0.897527  ...     -0.416839   -0.309120\nacceleration  0.423329  -0.504683  ...      1.000000    0.290316\nmodel_year    0.580541  -0.345647  ...      0.290316    1.000000\n\n[7 rows x 7 columns]\n\n\nIn the next two chapter we learn more about data preparation, analysis, and visualization with Python. For example, the statsmodels.formula.api module is used to create and fit a linear regression model. The formula for the regression model is defined using a string that specifies the dependent variable and the independent variables, separated by ~ operator which is very similar compared to R. The ols() method is used to create the model, passing in the formula and the dataset. Finally, the fit() method is used to fit the model to the data, and the summary() method is used to print a summary of the model results.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nresults = smf.ols('mpg ~ horsepower', data=cars).fit()\nprint(results.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    mpg   R-squared:                       0.606\nModel:                            OLS   Adj. R-squared:                  0.605\nMethod:                 Least Squares   F-statistic:                     599.7\nDate:                Thu, 18 Jan 2024   Prob (F-statistic):           7.03e-81\nTime:                        18:09:39   Log-Likelihood:                -1178.7\nNo. Observations:                 392   AIC:                             2361.\nDf Residuals:                     390   BIC:                             2369.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     39.9359      0.717     55.660      0.000      38.525      41.347\nhorsepower    -0.1578      0.006    -24.489      0.000      -0.171      -0.145\n==============================================================================\nOmnibus:                       16.432   Durbin-Watson:                   0.920\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               17.305\nSkew:                           0.492   Prob(JB):                     0.000175\nKurtosis:                       3.299   Cond. No.                         322.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\nUshey, Kevin, JJ Allaire, and Yuan Tang. 2023. “Reticulate: Interface to ’Python’.” https://CRAN.R-project.org/package=reticulate.\n\n\nWaskom, Michael L. 2021. “Seaborn: Statistical Data Visualization.” Journal of Open Source Software 6 (60): 3021. https://doi.org/10.21105/joss.03021."
  },
  {
    "objectID": "manipulation.html#filter",
    "href": "manipulation.html#filter",
    "title": "3  Data manipulation",
    "section": "3.1 Filter",
    "text": "3.1 Filter\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#Filter data\npenguins.query('species == \"Adelie\"').head()\n\n  species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n0  Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n1  Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n2  Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n4  Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n5  Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n\n[5 rows x 7 columns]\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#Filter data\npenguins.query('species == \"Adelie\" & sex == \"Male\" ').head()\n\n   species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g   sex\n0   Adelie  Torgersen            39.1  ...              181.0       3750.0  Male\n5   Adelie  Torgersen            39.3  ...              190.0       3650.0  Male\n7   Adelie  Torgersen            39.2  ...              195.0       4675.0  Male\n13  Adelie  Torgersen            38.6  ...              191.0       3800.0  Male\n14  Adelie  Torgersen            34.6  ...              198.0       4400.0  Male\n\n[5 rows x 7 columns]\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum."
  },
  {
    "objectID": "manipulation.html#arrange",
    "href": "manipulation.html#arrange",
    "title": "3  Data manipulation",
    "section": "3.2 Arrange",
    "text": "3.2 Arrange\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#Sort variables\npenguins.sort_values(by=\"body_mass_g\").head()\n\n       species     island  ...  body_mass_g     sex\n190  Chinstrap      Dream  ...       2700.0  Female\n64      Adelie     Biscoe  ...       2850.0  Female\n58      Adelie     Biscoe  ...       2850.0  Female\n116     Adelie  Torgersen  ...       2900.0  Female\n98      Adelie      Dream  ...       2900.0  Female\n\n[5 rows x 7 columns]\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#Sort variables descendingly\npenguins.sort_values(by=\"body_mass_g\", ascending=False).head()\n\n    species  island  bill_length_mm  ...  flipper_length_mm  body_mass_g   sex\n237  Gentoo  Biscoe            49.2  ...              221.0       6300.0  Male\n253  Gentoo  Biscoe            59.6  ...              230.0       6050.0  Male\n297  Gentoo  Biscoe            51.1  ...              220.0       6000.0  Male\n337  Gentoo  Biscoe            48.8  ...              222.0       6000.0  Male\n299  Gentoo  Biscoe            45.2  ...              223.0       5950.0  Male\n\n[5 rows x 7 columns]"
  },
  {
    "objectID": "manipulation.html#select",
    "href": "manipulation.html#select",
    "title": "3  Data manipulation",
    "section": "3.3 Select",
    "text": "3.3 Select\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#Select via []\npenguins[['species', 'island']].head()\n\n  species     island\n0  Adelie  Torgersen\n1  Adelie  Torgersen\n2  Adelie  Torgersen\n4  Adelie  Torgersen\n5  Adelie  Torgersen\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\npenguins.loc[:, 'island':'bill_depth_mm'].head()\n\n      island  bill_length_mm  bill_depth_mm\n0  Torgersen            39.1           18.7\n1  Torgersen            39.5           17.4\n2  Torgersen            40.3           18.0\n4  Torgersen            36.7           19.3\n5  Torgersen            39.3           20.6\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\nadelie = penguins[penguins[\"species\"].isin([\"Adelie\"])]\nadelie.head()\n\n  species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n0  Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n1  Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n2  Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n4  Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n5  Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n\n[5 rows x 7 columns]"
  },
  {
    "objectID": "manipulation.html#mutate",
    "href": "manipulation.html#mutate",
    "title": "3  Data manipulation",
    "section": "3.4 Mutate",
    "text": "3.4 Mutate\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\nweight = penguins[['body_mass_g']]\nweight = weight.assign(body_mass_kilo = weight['body_mass_g'] /1000)\nweight.head()\n\n   body_mass_g  body_mass_kilo\n0       3750.0            3.75\n1       3800.0            3.80\n2       3250.0            3.25\n4       3450.0            3.45\n5       3650.0            3.65"
  },
  {
    "objectID": "manipulation.html#summarize",
    "href": "manipulation.html#summarize",
    "title": "3  Data manipulation",
    "section": "3.5 Summarize",
    "text": "3.5 Summarize\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\npenguins.describe()\n\n       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\ncount      333.000000     333.000000         333.000000   333.000000\nmean        43.992793      17.164865         200.966967  4207.057057\nstd          5.468668       1.969235          14.015765   805.215802\nmin         32.100000      13.100000         172.000000  2700.000000\n25%         39.500000      15.600000         190.000000  3550.000000\n50%         44.500000      17.300000         197.000000  4050.000000\n75%         48.600000      18.700000         213.000000  4775.000000\nmax         59.600000      21.500000         231.000000  6300.000000\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\npenguins[[\"sex\", \"body_mass_g\"]].groupby(\"sex\").mean()\n\n        body_mass_g\nsex                \nFemale  3862.272727\nMale    4545.684524\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\npenguins.groupby([\"sex\", \"species\"])[\"body_mass_g\"].mean()\n\nsex     species  \nFemale  Adelie       3368.835616\n        Chinstrap    3527.205882\n        Gentoo       4679.741379\nMale    Adelie       4043.493151\n        Chinstrap    3938.970588\n        Gentoo       5484.836066\nName: body_mass_g, dtype: float64\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#shortr penguins[\"species\"].value_counts()\npenguins.groupby(\"species\")[\"species\"].count()\n\nspecies\nAdelie       146\nChinstrap     68\nGentoo       119\nName: species, dtype: int64\n\n\n\nREMEMBER\n\nAggregation statistics can be calculated on entire columns or rows.\ngroupby provides the power of the split-apply-combine pattern.\nvalue_counts is a convenient shortcut to count the number of entries in each category of a variable.\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\npenguins.loc[penguins['species'] == \"Adelie\", 'Adelie'] = 'True' \npenguins.loc[penguins['species'] != \"Adelie\", 'Adelie'] = 'False' \npenguins[['species', 'Adelie']].head()\n\n  species Adelie\n0  Adelie   True\n1  Adelie   True\n2  Adelie   True\n4  Adelie   True\n5  Adelie   True\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\npenguins['check_length'] = penguins['bill_length_mm'].apply(lambda x: 'True' if x &lt;= 40 else 'False')\npenguins[['bill_length_mm', 'check_length']].head()\n\n   bill_length_mm check_length\n0            39.1         True\n1            39.5         True\n2            40.3        False\n4            36.7         True\n5            39.3         True"
  },
  {
    "objectID": "visualization.html#categorical-data",
    "href": "visualization.html#categorical-data",
    "title": "4  Visualization",
    "section": "4.1 Categorical data",
    "text": "4.1 Categorical data\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#Bar graph\nsns.barplot(data=penguins, x=\"species\", y=\"bill_length_mm\")\n\n\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\n#Beeswarm\nsns.catplot(data=penguins, kind=\"swarm\", x=\"sex\", y=\"bill_length_mm\", hue=\"species\")"
  },
  {
    "objectID": "visualization.html#relationsships",
    "href": "visualization.html#relationsships",
    "title": "4  Visualization",
    "section": "4.2 Relationsships",
    "text": "4.2 Relationsships\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.style.use('ggplot')\n\nplt.scatter(penguins.body_mass_g, penguins.bill_length_mm)\n\n\n\n\nStet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\n\n#Scatterplot\nfrom plotnine import *\n(ggplot(penguins, aes('body_mass_g', 'bill_length_mm'))\n + geom_point()\n + stat_smooth(method='lm')\n + facet_wrap('~species'))\n\n\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\n\n#Histogram\n(ggplot(penguins, aes(x='body_mass_g'))\n    + geom_histogram()\n    )\n\n&lt;ggplot: (691307746)&gt;\n\n/Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 11'. Pick better value with 'binwidth'.\n\n\n\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\n\n# geom_boxplot\n(ggplot(penguins)\n  + geom_boxplot(aes(x='factor(species)', y='body_mass_g'))\n)\n\n&lt;ggplot: (691422570)&gt;"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ushey, Kevin, JJ Allaire, and Yuan Tang. 2023. “Reticulate:\nInterface to ’Python’.” https://CRAN.R-project.org/package=reticulate.\n\n\nWaskom, Michael L. 2021. “Seaborn: Statistical Data\nVisualization.” Journal of Open Source Software 6 (60):\n3021. https://doi.org/10.21105/joss.03021."
  }
]