---
title: "Introduction"
---

```{r setup, include=FALSE}
reticulate::use_python("/Users/edgar/Library/r-miniconda-arm64/envs/r-reticulate/bin/python")

knitr::opts_chunk$set(
  #fig.width = 6,
  #fig.height = 4,
  #fig.path = "images/",
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  eval = TRUE,
  comment = "#>"
)

```

This chapter aims to provide you with a brief overview of the book. We will discuss the motivation behind this book, the target audience, and the structure of the book. Formost, I try to outline how you can transfer your R knowledge to Python. 

What is my motivation to write this book? I tried to learn Python with the help of several books and classes. Coding and programming languages were not new for me, but still I failed to learn Python. I consider myself a tech-savvy without having a heavy programming background, but a lot of fun learning new things and enjoy coding. For this reason I started this book. If you want to learn Python to automate processes, apply statistical procedures from the scratch, or use Python to program games, this book will not help you in any way. However, you do wanna transfer your R knowledge, this book might be right choice. Let be give you an example why I started this book

## How (not) to calculate basic statistics {.unnumbered}

Before we can do anything, we have to install Python, learn how to manage virtual environments, and we how we can install packages. As with R, you have to install and import libraries for most tasks. We will cover these steps in the next chapter. For now, we will focus on some code snippets only. Say we use the seaborn package because it provides us with some data. We can use the mpg data set as cars and fool around with it. Only if you have never seen the mpg data set, you can use the following code snippet to get an overview of the data set.


```{python}
#import seaborn to get some data
import seaborn as sns

#use the mpg data set as cars
cars = sns.load_dataset("mpg") 
print(cars)
```



Suppose a mean function is not implemented in Python. We can create our own function to calculate the mean. We need to define a function that calculates the mean of an array. First, we have to define the function with the def keyword, followed by the name of the function and the input value. The function should return the sum of the array divided by the length of the array. 

```{python}
# Define 
def mean (array): 
    n = len(array)
    return sum(array) / n

#A
mean(cars.mpg)
```

That’s a cool way to show us how a function works. We have to provide a name of a function and tell Python what the function does. I always learned how functions and other concepts work in much more artificial way, especially in classes courses about Python. Look how I learned how a function works in Python:

```{python}
#Create a function that inserts the name of the input value into a sentence

def hello(name):
    return (f"Hallo, {name}! How are you?")

# Call the function and give it value as input
hello("Edgar")
```

Thus, we create the hello function that returns a sentence and inserts the name of the input value. Nothing wrong about that, even calculating a mean seems a little bit more realistic to illustrate why we need such a function. Anyway, in some classes I learned how to calculate the mean, the median, and the modus. Maybe a function to calculate the variance or others measure of central tendency. You know what Pearson R is? Guess what the next code does? And I guess you will skip the code after line 2, well that’s what recommend since the code only illustrates my point. The next console shows how to calculate the correlation coefficient between two arrays and I actually copied to code from a book. 


```{python}
import math
def correlation(x, y):
    n = len(x) 
    
    # Means
    x_mn = sum(x) / n 
    y_mn = sum(y) / n
    
    # Variance
    var_x = (1 / (n-1)) * sum(map(lambda xi: (xi - x_mn) ** 2 , x)) 
    var_y = (1 / (n-1)) * sum(map(lambda yi: (yi - y_mn) ** 2 , y))
    
    # Std
    std_x, std_y = math.sqrt(var_x), math.sqrt(var_y)
    
    # Covariance
    xy_var = map(lambda xi, yi: (xi - x_mn) * (yi - y_mn), x, y) 
    cov = (1 / (n-1)) * sum(xy_var)
    
    # Pearson's R
    r = cov / (std_x * std_y) 
    return float(f"{r:.3f}")

# Some data
size = [20, 15, 40, 25, 35]
cost = [300, 400, 600, 700, 666]

print(correlation(size, cost))
```


Please, use numpy to get the scientific toolkit and pandas for tabular processing and the presentation of data. The word numpy stands for numerical Python and is a package that provides us with a lot of functions to work with arrays. The pandas package is a data manipulation and analysis library that provides us with data structures and functions to manipulate data. We can use the numpy package to calculate the correlation coefficient between two arrays. The numpy package provides us with the corrcoef function that takes two arrays as input and returns the correlation coefficient. 


```{python}
# corrcoef function from numpy (short: np): 
import numpy as np
np.corrcoef(size, cost)
```


The pandas package provides us with the describe function that returns an overview of the data. We can use the mean and std functions to calculate the mean and standard deviation of the data. 



```{python}
import pandas as pd

cars.describe()
```


We have to append the describe() function to the saved cars data in order to get an overview of the central tendency measures. You can do the same with all other functions that calculate other measures, such as the mean or standard deviance:

```{python}
cars.mean()
cars.std()
```



And we should at least look at the scatter plot since we talk about correlations. The matplotlib provides a lot of different graphs for us. And in case you are an R user, you can even use the ggplot2 style, just to let you show some possibilities. But of course, we have to think more systematically how we can reach our goal in the next chapter.


```{python}
import matplotlib
import matplotlib.pyplot as plt
matplotlib.style.use('ggplot')

plt.scatter(cars.mpg, cars.horsepower)
```



## Summary

This chapter provided you with a brief overview of the book. We discussed the motivation behind this book, the target audience, and the structure of the book. We also outlined how you can transfer your R knowledge to Python. In the next chapter, we will discuss how to install Python, manage virtual environments, and install packages. 






